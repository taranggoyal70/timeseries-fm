{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Forecasting with Chronos-2 (Google Colab)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/Chronos2_Colab_Experiments.ipynb)\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "1. Do multivariate (MV) methods produce better predictions than univariate (UV) ones when foundation models are used?\n",
    "2. Is MV forecasting accuracy better for stocks versus interest rates?\n",
    "3. Is MV forecasting better when both stocks and interest rates are forecast together?\n",
    "4. Can we build a large-scale \"world\" forecasting model?\n",
    "\n",
    "---\n",
    "\n",
    "**Complete implementation per README specifications - Optimized for Google Colab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup: Install Dependencies\n",
    "\n",
    "**Run this first!** Installs all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q chronos-forecasting torch pandas numpy yfinance matplotlib seaborn tqdm python-dateutil\n",
    "\n",
    "print(\"âœ“ All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import yfinance as yf\n",
    "from chronos import Chronos2Pipeline\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Data Loader Class\n",
    "\n",
    "Downloads Magnificent-7 stocks and FRED interest rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Load and prepare financial time series data for Chronos-2 experiments.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Magnificent-7 stocks\n",
    "        self.mag7_tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"TSLA\", \"NVDA\"]\n",
    "        \n",
    "        # FRED interest rate series (10 maturities per README)\n",
    "        self.fred_series = {\n",
    "            \"DGS3MO\": \"3-Month\",\n",
    "            \"DGS6MO\": \"6-Month\",\n",
    "            \"DGS1\": \"1-Year\",\n",
    "            \"DGS2\": \"2-Year\",\n",
    "            \"DGS3\": \"3-Year\",\n",
    "            \"DGS5\": \"5-Year\",\n",
    "            \"DGS7\": \"7-Year\",\n",
    "            \"DGS10\": \"10-Year\",\n",
    "            \"DGS20\": \"20-Year\",\n",
    "            \"DGS30\": \"30-Year\"\n",
    "        }\n",
    "    \n",
    "    def download_stocks(self, start_date=\"2000-01-01\", end_date=None):\n",
    "        \"\"\"Download Magnificent-7 stock data from Yahoo Finance.\"\"\"\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        print(f\"Downloading Magnificent-7 stocks ({start_date} to {end_date})...\")\n",
    "        \n",
    "        df = yf.download(self.mag7_tickers, start=start_date, end=end_date, \n",
    "                       auto_adjust=True, progress=False)\n",
    "        \n",
    "        # Extract close prices\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df_close = df[\"Close\"].copy()\n",
    "        else:\n",
    "            df_close = df.copy()\n",
    "        \n",
    "        # Reset index and clean\n",
    "        df_close = df_close.reset_index()\n",
    "        df_close = df_close.rename(columns={\"Date\": \"timestamp\"})\n",
    "        df_close[\"timestamp\"] = pd.to_datetime(df_close[\"timestamp\"])\n",
    "        \n",
    "        # Business day frequency with forward fill\n",
    "        df_close = df_close.set_index(\"timestamp\").asfreq(\"B\").ffill().reset_index()\n",
    "        \n",
    "        print(f\"âœ“ Downloaded {len(df_close)} rows for {len(self.mag7_tickers)} stocks\")\n",
    "        return df_close\n",
    "    \n",
    "    def download_interest_rates(self, start_date=\"2000-01-01\", end_date=None):\n",
    "        \"\"\"Download FRED interest rate data.\"\"\"\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        print(f\"\\nDownloading FRED interest rates ({start_date} to {end_date})...\")\n",
    "        \n",
    "        all_rates = []\n",
    "        \n",
    "        for ticker, name in self.fred_series.items():\n",
    "            try:\n",
    "                # Try direct FRED CSV download\n",
    "                url = f\"https://fred.stlouisfed.org/graph/fredgraph.csv?id={ticker}\"\n",
    "                df = pd.read_csv(url, parse_dates=[\"DATE\"])\n",
    "                df = df.rename(columns={\"DATE\": \"timestamp\", ticker: ticker})\n",
    "                df = df.set_index(\"timestamp\")\n",
    "                df = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "                \n",
    "                # Replace '.' with NaN\n",
    "                df[ticker] = pd.to_numeric(df[ticker], errors='coerce')\n",
    "                \n",
    "                all_rates.append(df[ticker])\n",
    "                print(f\"âœ“ Downloaded {name} ({ticker})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âœ— Failed to download {ticker}: {e}\")\n",
    "        \n",
    "        if not all_rates:\n",
    "            raise ValueError(\"Could not download any interest rate data\")\n",
    "        \n",
    "        # Combine all rates\n",
    "        df_rates = pd.concat(all_rates, axis=1)\n",
    "        df_rates = df_rates.reset_index()\n",
    "        df_rates = df_rates.rename(columns={\"index\": \"timestamp\"})\n",
    "        df_rates[\"timestamp\"] = pd.to_datetime(df_rates[\"timestamp\"])\n",
    "        \n",
    "        # Business day frequency with forward fill\n",
    "        df_rates = df_rates.set_index(\"timestamp\").asfreq(\"B\").ffill().reset_index()\n",
    "        \n",
    "        print(f\"âœ“ Combined {len(df_rates)} rows for {len(all_rates)} interest rates\")\n",
    "        return df_rates\n",
    "    \n",
    "    def download_combined(self, start_date=\"2000-01-01\", end_date=None):\n",
    "        \"\"\"Download and combine stocks + interest rates (K=17).\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DOWNLOADING COMBINED DATASET (Stocks + Interest Rates)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        stocks = self.download_stocks(start_date, end_date)\n",
    "        rates = self.download_interest_rates(start_date, end_date)\n",
    "        \n",
    "        # Merge on timestamp\n",
    "        combined = pd.merge(stocks, rates, on=\"timestamp\", how=\"inner\")\n",
    "        \n",
    "        print(f\"\\nâœ“ Combined dataset: {len(combined)} rows, {len(combined.columns)-1} series (K=17)\")\n",
    "        return combined\n",
    "\n",
    "print(\"âœ“ DataLoader class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Metrics Calculator\n",
    "\n",
    "Implements RMSE and MAPE per README formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCalculator:\n",
    "    \"\"\"Calculate forecast error metrics per README specifications.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_rmse(actual, predicted):\n",
    "        \"\"\"\n",
    "        RMSE = [1/m * sum((x - y)^2)]^(1/2)\n",
    "        \"\"\"\n",
    "        m = len(actual)\n",
    "        squared_errors = (actual - predicted) ** 2\n",
    "        rmse = np.sqrt(np.mean(squared_errors))\n",
    "        return float(rmse)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_mape(actual, predicted):\n",
    "        \"\"\"\n",
    "        MAPE = 1/m * sum(|x - y| / |x|) * 100\n",
    "        \"\"\"\n",
    "        # Avoid division by zero\n",
    "        mask = actual != 0\n",
    "        if not mask.any():\n",
    "            return np.inf\n",
    "        \n",
    "        actual_masked = actual[mask]\n",
    "        predicted_masked = predicted[mask]\n",
    "        \n",
    "        absolute_percentage_errors = np.abs((actual_masked - predicted_masked) / actual_masked)\n",
    "        mape = np.mean(absolute_percentage_errors) * 100\n",
    "        return float(mape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_all_metrics(actual, predicted):\n",
    "        return {\n",
    "            'rmse': MetricsCalculator.calculate_rmse(actual, predicted),\n",
    "            'mape': MetricsCalculator.calculate_mape(actual, predicted)\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def compare_uv_mv_metrics(uv_metrics, mv_metrics):\n",
    "        rmse_improvement = ((uv_metrics['rmse'] - mv_metrics['rmse']) / uv_metrics['rmse']) * 100\n",
    "        mape_improvement = ((uv_metrics['mape'] - mv_metrics['mape']) / uv_metrics['mape']) * 100\n",
    "        \n",
    "        return {\n",
    "            'uv_rmse': uv_metrics['rmse'],\n",
    "            'mv_rmse': mv_metrics['rmse'],\n",
    "            'rmse_improvement_pct': rmse_improvement,\n",
    "            'uv_mape': uv_metrics['mape'],\n",
    "            'mv_mape': mv_metrics['mape'],\n",
    "            'mape_improvement_pct': mape_improvement,\n",
    "            'mv_better_rmse': mv_metrics['rmse'] < uv_metrics['rmse'],\n",
    "            'mv_better_mape': mv_metrics['mape'] < uv_metrics['mape']\n",
    "        }\n",
    "\n",
    "print(\"âœ“ MetricsCalculator class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Chronos-2 Experiment Runner\n",
    "\n",
    "Main class for running UV vs MV experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronosExperimentRunner:\n",
    "    \"\"\"Run Chronos-2 forecasting experiments per README specifications.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_size=\"base\", device=\"cuda\"):\n",
    "        self.model_size = model_size\n",
    "        self.metrics_calc = MetricsCalculator()\n",
    "        \n",
    "        # Load Chronos-2 model\n",
    "        print(f\"Loading Chronos-2 {model_size} model...\")\n",
    "        device = device if torch.cuda.is_available() else \"cpu\"\n",
    "        self.pipeline = Chronos2Pipeline.from_pretrained(\n",
    "            f\"amazon/chronos-2-{model_size}\",\n",
    "            device_map=device\n",
    "        )\n",
    "        print(f\"âœ“ Model loaded on {device}\")\n",
    "    \n",
    "    def prepare_data_for_date(self, df, target_date, n, m):\n",
    "        \"\"\"Prepare context and test data for a specific date.\"\"\"\n",
    "        df = df.copy()\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.sort_values('timestamp')\n",
    "        \n",
    "        # Find index of target date\n",
    "        target_idx = df[df['timestamp'] <= target_date].index[-1]\n",
    "        \n",
    "        # Context: n days before target_date\n",
    "        context_start_idx = max(0, target_idx - n + 1)\n",
    "        context_df = df.iloc[context_start_idx:target_idx+1].copy()\n",
    "        \n",
    "        # Test: m days after target_date\n",
    "        test_start_idx = target_idx + 1\n",
    "        test_end_idx = min(len(df), test_start_idx + m)\n",
    "        test_df = df.iloc[test_start_idx:test_end_idx].copy()\n",
    "        \n",
    "        return context_df, test_df\n",
    "    \n",
    "    def forecast_univariate(self, context_df, target_column, prediction_length):\n",
    "        \"\"\"Univariate forecast for single series.\"\"\"\n",
    "        context_uv = context_df[[\"item_id\", \"timestamp\", target_column]].copy()\n",
    "        \n",
    "        future_df = pd.DataFrame({\n",
    "            \"item_id\": context_uv[\"item_id\"].iloc[-1],\n",
    "            \"timestamp\": pd.date_range(\n",
    "                start=context_uv[\"timestamp\"].iloc[-1] + pd.Timedelta(days=1),\n",
    "                periods=prediction_length,\n",
    "                freq=\"B\"\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        pred_df = self.pipeline.predict_df(\n",
    "            context_uv,\n",
    "            future_df=future_df,\n",
    "            prediction_length=prediction_length,\n",
    "            quantile_levels=[0.1, 0.5, 0.9],\n",
    "            id_column=\"item_id\",\n",
    "            timestamp_column=\"timestamp\",\n",
    "            target=target_column\n",
    "        )\n",
    "        \n",
    "        return pred_df\n",
    "    \n",
    "    def forecast_multivariate(self, context_df, target_column, prediction_length):\n",
    "        \"\"\"\n",
    "        Multivariate forecast using all series.\n",
    "        IMPORTANT: No future covariate values - Chronos-2 learns from historical relationships.\n",
    "        \"\"\"\n",
    "        # Create future_df with ONLY timestamp and item_id\n",
    "        future_df = pd.DataFrame({\n",
    "            \"item_id\": context_df[\"item_id\"].iloc[-1],\n",
    "            \"timestamp\": pd.date_range(\n",
    "                start=context_df[\"timestamp\"].iloc[-1] + pd.Timedelta(days=1),\n",
    "                periods=prediction_length,\n",
    "                freq=\"B\"\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        pred_df = self.pipeline.predict_df(\n",
    "            context_df,\n",
    "            future_df=future_df,\n",
    "            prediction_length=prediction_length,\n",
    "            quantile_levels=[0.1, 0.5, 0.9],\n",
    "            id_column=\"item_id\",\n",
    "            timestamp_column=\"timestamp\",\n",
    "            target=target_column\n",
    "        )\n",
    "        \n",
    "        return pred_df\n",
    "    \n",
    "    def run_single_experiment(self, df, target_date, n, m, series_name, dataset_type):\n",
    "        \"\"\"Run single UV vs MV experiment.\"\"\"\n",
    "        # Prepare data\n",
    "        context_df, test_df = self.prepare_data_for_date(df, target_date, n, m)\n",
    "        \n",
    "        if len(test_df) < m:\n",
    "            return None\n",
    "        \n",
    "        # Add item_id if not present\n",
    "        if 'item_id' not in context_df.columns:\n",
    "            context_df['item_id'] = dataset_type\n",
    "            test_df['item_id'] = dataset_type\n",
    "        \n",
    "        # Run forecasts\n",
    "        uv_pred = self.forecast_univariate(context_df, series_name, m)\n",
    "        mv_pred = self.forecast_multivariate(context_df, series_name, m)\n",
    "        \n",
    "        # Get actual values\n",
    "        actual = test_df.set_index(\"timestamp\")[series_name].values[:m]\n",
    "        uv_values = uv_pred[series_name].values[:m]\n",
    "        mv_values = mv_pred[series_name].values[:m]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        uv_metrics = self.metrics_calc.calculate_all_metrics(actual, uv_values)\n",
    "        mv_metrics = self.metrics_calc.calculate_all_metrics(actual, mv_values)\n",
    "        comparison = self.metrics_calc.compare_uv_mv_metrics(uv_metrics, mv_metrics)\n",
    "        \n",
    "        result = {\n",
    "            'dataset': dataset_type,\n",
    "            'series': series_name,\n",
    "            'target_date': target_date.strftime('%Y-%m-%d'),\n",
    "            'n': n,\n",
    "            'm': m,\n",
    "            'alpha': n / 252,\n",
    "            **comparison,\n",
    "            'actual_values': actual.tolist(),\n",
    "            'uv_predictions': uv_values.tolist(),\n",
    "            'mv_predictions': mv_values.tolist()\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"âœ“ ChronosExperimentRunner class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Step 1: Download Data\n",
    "\n",
    "Download Magnificent-7 stocks and FRED interest rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Download all datasets\n",
    "print(\"Downloading data from 2000-01-01 to present...\\n\")\n",
    "\n",
    "stocks_df = loader.download_stocks(start_date=\"2000-01-01\")\n",
    "rates_df = loader.download_interest_rates(start_date=\"2000-01-01\")\n",
    "combined_df = loader.download_combined(start_date=\"2000-01-01\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Stocks: {stocks_df.shape[0]} rows, {stocks_df.shape[1]-1} series (K=7)\")\n",
    "print(f\"Interest Rates: {rates_df.shape[0]} rows, {rates_df.shape[1]-1} series (K=10)\")\n",
    "print(f\"Combined: {combined_df.shape[0]} rows, {combined_df.shape[1]-1} series (K=17)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "print(\"\\nStocks (Magnificent-7):\")\n",
    "display(stocks_df.head())\n",
    "\n",
    "print(\"\\nInterest Rates (FRED):\")\n",
    "display(rates_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Step 2: Single Test Experiment\n",
    "\n",
    "Per README: n=252, m=21, t=03/31/2025, test with NVDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize experiment runner\n",
    "runner = ChronosExperimentRunner(model_size=\"base\")\n",
    "\n",
    "# Prepare test data\n",
    "stocks_df['item_id'] = 'stocks'\n",
    "test_date = datetime(2025, 3, 31)\n",
    "n = 252  # 1 year\n",
    "m = 21   # 1 month\n",
    "\n",
    "print(f\"\\nTest Experiment:\")\n",
    "print(f\"  Date: {test_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"  History (n): {n} days\")\n",
    "print(f\"  Forecast (m): {m} days\")\n",
    "print(f\"  Series: NVDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test experiment\n",
    "result = runner.run_single_experiment(\n",
    "    df=stocks_df,\n",
    "    target_date=test_date,\n",
    "    n=n,\n",
    "    m=m,\n",
    "    series_name='NVDA',\n",
    "    dataset_type='stocks'\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nUnivariate (UV):\")\n",
    "    print(f\"  RMSE: {result['uv_rmse']:.4f}\")\n",
    "    print(f\"  MAPE: {result['uv_mape']:.2f}%\")\n",
    "    print(f\"\\nMultivariate (MV):\")\n",
    "    print(f\"  RMSE: {result['mv_rmse']:.4f}\")\n",
    "    print(f\"  MAPE: {result['mv_mape']:.2f}%\")\n",
    "    print(f\"\\nImprovement:\")\n",
    "    print(f\"  RMSE: {result['rmse_improvement_pct']:.2f}%\")\n",
    "    print(f\"  MAPE: {result['mape_improvement_pct']:.2f}%\")\n",
    "    print(f\"  MV Better: {result['mv_better_mape']}\")\n",
    "else:\n",
    "    print(\"Test failed - check data availability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test results\n",
    "if result:\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    timestamps = pd.date_range(start=test_date, periods=m+1, freq='B')[1:]\n",
    "    \n",
    "    ax.plot(timestamps, result['actual_values'], 'ko-', label='Actual', linewidth=2, markersize=6)\n",
    "    ax.plot(timestamps, result['uv_predictions'], 'b^--', label='UV Forecast', linewidth=2, markersize=6)\n",
    "    ax.plot(timestamps, result['mv_predictions'], 'rs--', label='MV Forecast', linewidth=2, markersize=6)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('NVDA Stock Price ($)', fontsize=12)\n",
    "    ax.set_title(f'NVDA Forecast: UV vs MV (n={n}, m={m})', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ Test experiment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 3: Run Multiple Experiments\n",
    "\n",
    "**Note:** Full experiments take a long time. Start with a small subset for testing.\n",
    "\n",
    "For full experiments per README:\n",
    "- Î± = {0.5, 1, 2, 3}\n",
    "- m = {21, 63}\n",
    "- Monthly rolling from 2000-2025\n",
    "- All 7 stocks or 10 rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Run experiments for 2 stocks, 1 parameter combo, quarterly 2024\n",
    "test_stocks = ['AAPL', 'NVDA']\n",
    "alpha = 1.0  # n = 252\n",
    "m = 21       # 1 month\n",
    "\n",
    "# Generate quarterly dates in 2024\n",
    "forecast_dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='QS')\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"\\nRunning experiments:\")\n",
    "print(f\"  Series: {test_stocks}\")\n",
    "print(f\"  n={int(alpha*252)}, m={m}\")\n",
    "print(f\"  Dates: {len(forecast_dates)} quarterly dates in 2024\")\n",
    "print(f\"  Total: {len(test_stocks) * len(forecast_dates)} experiments\\n\")\n",
    "\n",
    "for series_name in test_stocks:\n",
    "    for target_date in tqdm(forecast_dates, desc=f\"Forecasting {series_name}\"):\n",
    "        try:\n",
    "            result = runner.run_single_experiment(\n",
    "                df=stocks_df,\n",
    "                target_date=target_date,\n",
    "                n=int(alpha*252),\n",
    "                m=m,\n",
    "                series_name=series_name,\n",
    "                dataset_type='stocks'\n",
    "            )\n",
    "            if result:\n",
    "                results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {series_name}, {target_date}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ“ Completed {len(results)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "if results:\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXPERIMENT SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    mv_win_rate = (df_results['mv_better_mape'].sum() / len(df_results)) * 100\n",
    "    print(f\"\\nMV Win Rate (MAPE): {mv_win_rate:.1f}%\")\n",
    "    \n",
    "    avg_mape_improvement = df_results['mape_improvement_pct'].mean()\n",
    "    print(f\"Average MAPE Improvement: {avg_mape_improvement:.2f}%\")\n",
    "    \n",
    "    print(\"\\nBy Series:\")\n",
    "    series_summary = df_results.groupby('series').agg({\n",
    "        'mv_better_mape': 'mean',\n",
    "        'mape_improvement_pct': 'mean',\n",
    "        'uv_mape': 'mean',\n",
    "        'mv_mape': 'mean'\n",
    "    }).round(2)\n",
    "    series_summary.columns = ['MV Win Rate', 'Avg MAPE Improvement %', 'Avg UV MAPE', 'Avg MV MAPE']\n",
    "    display(series_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "if results:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # MV Win Rate by Series\n",
    "    win_rates = df_results.groupby('series')['mv_better_mape'].mean() * 100\n",
    "    axes[0].bar(win_rates.index, win_rates.values, color='steelblue')\n",
    "    axes[0].set_ylabel('MV Win Rate (%)', fontsize=12)\n",
    "    axes[0].set_title('MV Win Rate by Series', fontsize=13, fontweight='bold')\n",
    "    axes[0].axhline(y=50, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAPE Improvement\n",
    "    improvements = df_results.groupby('series')['mape_improvement_pct'].mean()\n",
    "    axes[1].bar(improvements.index, improvements.values, color='coral')\n",
    "    axes[1].set_ylabel('Avg MAPE Improvement (%)', fontsize=12)\n",
    "    axes[1].set_title('Average MAPE Improvement', fontsize=13, fontweight='bold')\n",
    "    axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Results\n",
    "\n",
    "Save to Google Drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to JSON\n",
    "if results:\n",
    "    # Save to Colab's local storage\n",
    "    with open('experiment_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(\"âœ“ Saved to experiment_results.json\")\n",
    "    \n",
    "    # Save summary to CSV\n",
    "    summary_results = []\n",
    "    for r in results:\n",
    "        summary = {k: v for k, v in r.items() \n",
    "                  if k not in ['actual_values', 'uv_predictions', 'mv_predictions']}\n",
    "        summary_results.append(summary)\n",
    "    \n",
    "    df_summary = pd.DataFrame(summary_results)\n",
    "    df_summary.to_csv('experiment_summary.csv', index=False)\n",
    "    print(\"âœ“ Saved to experiment_summary.csv\")\n",
    "    \n",
    "    # Download files\n",
    "    from google.colab import files\n",
    "    files.download('experiment_results.json')\n",
    "    files.download('experiment_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Research Question Answers\n",
    "\n",
    "Based on your experimental results, answer:\n",
    "\n",
    "1. **Do MV methods produce better predictions than UV with foundation models?**\n",
    "   - [Fill in based on MV win rate and MAPE improvements]\n",
    "\n",
    "2. **Is MV forecasting accuracy better for stocks versus interest rates?**\n",
    "   - [Compare stocks vs rates experiments]\n",
    "\n",
    "3. **Is MV forecasting better when both stocks and interest rates are forecast together?**\n",
    "   - [Compare combined (K=17) vs separate experiments]\n",
    "\n",
    "4. **Can we build a large-scale \"world\" forecasting model?**\n",
    "   - [Discuss scalability based on K=17 results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Next Steps\n",
    "\n",
    "**For full experiments per README:**\n",
    "\n",
    "1. Modify the experiment loop to use:\n",
    "   - All 7 stocks: `['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA']`\n",
    "   - All Î± values: `[0.5, 1.0, 2.0, 3.0]`\n",
    "   - Both m values: `[21, 63]`\n",
    "   - Monthly rolling from 2000-2025\n",
    "\n",
    "2. Run experiments for:\n",
    "   - Stocks (K=7)\n",
    "   - Interest rates (K=10)\n",
    "   - Combined (K=17)\n",
    "\n",
    "3. Analyze and compare results\n",
    "\n",
    "**Warning:** Full experiments will take many hours. Use GPU runtime for faster execution."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
